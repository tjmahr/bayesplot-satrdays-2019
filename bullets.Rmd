---
title: "bayesplot"
subtitle: "Diagnostic plots for Bayesian models"
author: "TJ Mahr<br/>UW--Madison Waisman Center"
output: 
  revealjs::revealjs_presentation: 
    keep_md: true
    theme: simple
    self_contained: true
    css: 
      - align-left.css
  rmarkdown::github_document: default
---

```{r setup, include = FALSE}
library(tidyverse)
library(rstanarm)
library(tidybayes)
library(bayesplot)

fig_width <- 6
fig_height <- 4
fig_width <- 4.5
fig_height <- 3

knitr::opts_chunk$set(
  echo = TRUE, 
  comment = "#>", 
  collapse = TRUE, 
  dpi = 600, 
  fig.width = fig_width, 
  fig.height = fig_height,
  warning = FALSE,
  cache = TRUE
)

options(htmltools.dir.version = FALSE)

# ggtitle <- function(x) {
#   labs(tag = x)
# }

# extrafont::loadfonts(device = "postscript")
extrafont::loadfonts(device = "win")

bayesplot_theme_replace(
  plot.caption = element_text(size = rel(1)),
  plot.title = element_text(
    family = "Consolas", hjust = 0, size = rel(.8), 
    margin = margin(0, 0, 5.5, 0, unit = "pt"))
)

self_title <- function(expr) {
  p <- rlang::enexpr(expr)
  title <- rlang::quo_text(p) %>% 
    styler::style_text() %>% 
    as.character() %>% 
    stringr::str_replace_all(" [+] ", " +\n  ") %>% 
    paste0(collapse = "\n")

  eval(p) + ggtitle(title)
}


```

```{r setup-data, include = FALSE}
races_raw <- readr::read_tsv("data/scottish-hill-races.txt") %>%
  janitor::clean_names() %>%
  filter(!is.na(mens_time_min)) %>%
  mutate(
    climb_km = climb_m / 1000,
    time_min = if_else(
      mens_time_min < womens_time_min, 
      mens_time_min, 
      womens_time_min, 
      missing = mens_time_min
    )
  ) 

races <- races_raw %>% 
  select(race, distance_km, climb_km, time_min)
```


```{r setup-models, include = FALSE}
m1 <- stan_glm(
  time_min ~ distance_km,
  data = races,
  family = gaussian,
  prior = normal(0, 1, autoscale = TRUE)
)

m2 <- stan_glm(
  time_min ~ distance_km * climb_km,
  data = races,
  family = gaussian,
  prior = normal(0, 1, autoscale = TRUE)
)

# Change outcome measure to get chains sampling a different parameter space
m1_spoof <- stan_glm(
  womens_time_min ~ distance_km,
  data = races_raw,
  family = gaussian,
  prior = normal(0, 1, autoscale = TRUE)
)

# Overwrite some draws in chain 2 to simulate bad mixing
bad_chains <- as.array(m1)
bad_chains[1:300, 2, ] <- as.array(m1_spoof)[1:300, 2, ]

# multilevel model example
m_eight_schools <- shinystan::eight_schools@posterior_sample

d_fitted_distances <- races %>% 
  tidyr::expand(
    distance_km = seq(min(distance_km), max(distance_km), length.out = 100)
  ) %>% 
  tidybayes::add_fitted_draws(m1, n = 50)
```


## {data-background-iframe="https://kidspeech.wisc.edu/other-projects/communciation-development-in-school-age-children-with-cerebral-palsy/"}

  <!-- - I study how children with motor disabilities learn to speak and communicate -->
  <!-- - I work with repeated-measures time-series data from a heterogenous -->
  <!--   population -->
  <!-- - Bayesian models provide a flexible and coherent framework for modeling this -->
  <!--   data -->

<div style="position: absolute; width: 60%; top: 300px; right: 0px; box-shadow: 0 1px 4px rgba(0,0,0,0.5), 0 5px 25px rgba(0,0,0,0.2); background-color: rgba(223, 233, 245, 1); padding: 20px; font-size: 30px; text-align: left;">

Hello! ðŸ‘‹

I study how children with motor disorders learn to speak and communicate.

Bayesian stats let me handle repeated-measures, time-series data from
heterogeneous populations.

</div>


## My current modeling project

```{r my-current-project, echo = FALSE, out.width="100%", fig.cap = "My current project looks at speech intelligibility (y) changes with age (x). The figure shows a spaghetti plot of model fits and observed data for one child, showing a nice fit to the data. The right shows three histograms that describe when the lines cross various intelligibility thresholds."}
knitr::include_graphics("my-current-project.png")
```


---

To get my cool model to work, I needed diagnostics...

```{r packages-demo}
library(ggplot2)
library(bayesplot)
```

- Plotting functions for visual diagnostics and model criticism
- Part of the Stan universe but works with generic MCMC samples
- Built on top of ggplot2
- Simple functions to make routine visualization easy
- https://mc-stan.org/bayesplot/



## Scottish Hill races

Try to predict race time from race distance and hill height.

`stan_glm(time_min ~ distance_km, data = races, ...)`

```{r races-data}
races
```



## Bayesian models in 15 seconds

**Classical regression**: line of best fit (*maximum likelihood*)

**Bayesian regression**: all plausible lines given data and data-generating 
process (*posterior distribution*)


## Model is a distribution {data-background=#ee00ee}

## Marginal distributions of parameters

```{r hist, echo = FALSE, message = FALSE, fig.cap="Three facets showing histograms of posterior samples for the model's intercept, main predictor (distance) and the error term sigma."}
m1_draws <- as.matrix(m1) 
self_title(
  mcmc_hist(m1_draws)
)
```

## Uncertainty/compatibility intervals

```{r intervals, echo = FALSE, message = FALSE, fig.cap="Plot showing the median and two compatibility intervals for each parameter. We use this compare the sign and magnitude of model parameters."}
self_title(
  mcmc_intervals(m1_draws) 
)
```

## Maybe you can do better? Go for it.

```{r intervals-data, echo = TRUE, message = FALSE}
mcmc_intervals_data(m1_draws) %>% 
  glimpse()
```

## Intervals plus density

```{r areas, echo = FALSE, message = FALSE, fig.width = fig_width + .5, fig.cap="Like the previous interval plot but with density curves drawn instead."}
self_title(
  mcmc_areas(m1_draws, area_method = "equal height") 
)
```


## Ridgelines help hierarchical models


```{r ridgelines, echo = FALSE, message = FALSE, fig.cap="A set of several partially overlapping density curves with shaded areas showing 80% intervals."}
color_scheme_set("red")
self_title(
  mcmc_areas_ridges(m_eight_schools, prob = .8) + 
    geom_vline(xintercept = 0) 
)
color_scheme_set("blue")
```



## Joint distributions

<!-- Those other views are looking at the side of hill. We can look from above too. -->

```{r scatter, echo = FALSE, fig.width = 6, fig.height = 4, fig.cap="A scatterplot of posterior draws of the intercept and distance effect with contour lines overlaid."}
self_title(
  mcmc_scatter(m1_draws, c("(Intercept)", "distance_km"), alpha = 0.15) + 
    stat_density_2d(color = "black", size = .25)
)
```

## Hex bin

```{r hex, echo = FALSE, fig.width = 6, fig.height = 4, fig.cap="Another 2-d density plot but this one uses hexagonal tiles and uses shading to show density."}
self_title(
  mcmc_hex(m1_draws, pars = c("(Intercept)", "distance_km"))
)
```




## Model is generative {data-background=#ee00ee}


## Bayesian models are generative

  - You specify a data-generating process.
  - Model provides a sample of parameter values for the process that are
    compatible with the data.

### Posterior predictive checks

  - On each draw of posterior distribution, have the model re-predict the
    original dataset.
  - **Does the replicated data look like the original data?**

## Boxplot of observed versus 6 replications

```{r ppc-boxplot, echo = FALSE, message = FALSE, fig.cap = "Boxplot of observed versus 6 replications"}
m1_yrep_50 <- posterior_predict(m1, draws = 50)
m1_yrep_6 <- posterior_predict(m1, draws = 6)
self_title(
  ppc_boxplot(y = m1$y, yrep = m1_yrep_6) + geom_hline(yintercept = 0)
)
```

## Density of observed versus 50 replications

```{r ppc-dens-overlay, echo = FALSE, message = FALSE, fig.cap = "Density of observed versus 50 replications. The model replications do not agree with the data."}
self_title(
  ppc_dens_overlay(y = m1$y, yrep = m1_yrep_50) + 
    labs(caption = "time_min ~ distance_km")
) 
```

## Density from a better model

```{r ppc-dens-overlay2, echo = FALSE, message = FALSE, fig.cap = "Density of observed versus 50 replications. The model replications agree with the data."}
m2_yrep2_50 <- posterior_predict(m2, draws = 50)
color_scheme_set("purple")

self_title(
  ppc_dens_overlay(y = m1$y, yrep = m2_yrep2_50) + 
    labs(caption = "time_min ~ distance_km * climb_km")  
)

color_scheme_set("blue")
```


## How well are individual data points predicted?

```{r ppc-intervals, echo = FALSE, fig.width = 6, fig.height = 4, fig.cap = "Plot of the observed data by distance. For each observation, there is a 95% interval showing the model's range of simulations. As the distance increases, the intervals get farther from the observations, more or less."}
m1_yrep_1000 <- posterior_predict(m1, draws = 1000)

self_title(
  ppc_intervals(
    y = m1$y, 
    yrep = m1_yrep_1000, 
    x = races$distance_km, 
    prob_outer = .95
  ) + 
    xlab("distance_km")
)
```


## Pointwise prediction error

```{r ppc-error-scatter-avg-vs-x, echo = FALSE, message = FALSE, fig.width = 6.25, fig.height = 4, fig.cap = "Instead of showing observed versus simulation, this shows the average of observed minus simulated. The x axis is hill height. A LOESS smooth shows that error increases with hill height."}
self_title(
  ppc_error_scatter_avg_vs_x(
    y = m1$y,
    yrep = m1_yrep_1000, 
    x = races$climb_km
  ) + 
  stat_smooth(color = "grey30") + 
  xlab("climb_km")
)
```

## Model's distribution comes from a sampling algorithm {data-background=#9BA7B0}

---

- Bayesian models are estimated by Markov Chain Monte Carlo. 
- Multiple *chains* sample the posterior distribution in parallel.
- **Did these chains adequately sample the posterior distribution?**


## Classic traceplot ðŸ›

```{r traceplot, echo = FALSE, message = FALSE, fig.cap = "The canonical traceplot. It looks like a hairy caterpillar. It's good."}
self_title(
  mcmc_trace(as.array(m1), pars = "distance_km")
)
```

## Traceplot with bad mixing of chains

```{r bad-trace, echo = FALSE, message = FALSE, fig.cap = "Traceplot where one of the chains gets stuck. It's bad."}
self_title(
  mcmc_trace(bad_chains, "distance_km")
)
```

## New diagnostics are coming

```{r new-rhat, out.width="100%", echo = FALSE, fig.cap = "Figure showing the abstract of the new Rhat paper. https://arxiv.org/abs/1903.08008"}
knitr::include_graphics("new-rhat.png")
```

## [wip] Do *ranks* mix well among chains?

```{r rank-trace, echo = FALSE, message = FALSE, fig.cap = "Figure showing mixture of rankings among the chains from the bad traceplot. Chain 2 dominates one end of the rankings."}
# remotes::install_github(
#   "stan-dev/bayesplot",
#   ref = remotes::github_pull(179)
# )
self_title(
  mcmc_rank_overlay(bad_chains, "distance_km")
)
```

## {data-background-iframe="https://mc-stan.org/bayesplot/"}

<div style="position: absolute; width: 60%; right: 0; box-shadow: 0 1px 4px rgba(0,0,0,0.5), 0 5px 25px rgba(0,0,0,0.2); background-color: rgba(223, 233, 245, 1); padding: 20px; font-size: 40px; text-align: left;">

Plus dozens more plots

https://mc-stan.org/bayesplot/

</div>


## Acknowledgments

* Shoutout to Jonah Gabry, the lead author of the package
* Rest of Stan team.
* My work is supported by NIH R01DC009411, R01DC015653

https://github.com/tjmahr/bayesplot-satrdays-2019
